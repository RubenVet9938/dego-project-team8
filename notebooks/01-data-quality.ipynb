{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888088f2",
   "metadata": {},
   "source": [
    "# Data Quality Analysis: NovaCred Credit Applications\n",
    "\n",
    "**Dataset:** `raw_credit_applications.json`: 500+ loan application records  \n",
    "\n",
    "## Scope\n",
    "\n",
    "This notebook covers nine data quality issue categories:\n",
    "\n",
    "| Section | Issue Category | Dimension |\n",
    "|---------|---------------|-----------|\n",
    "| 1 | Duplicate records | Accuracy |\n",
    "| 2 | Missing / incomplete records | Completeness |\n",
    "| 3 | Inconsistent data types | Consistency |\n",
    "| 4 | Invalid or impossible values | Validity |\n",
    "| 5 | Inconsistent categorical coding (gender) | Consistency |\n",
    "| 6 | Inconsistent date formats (date of birth) | Consistency |\n",
    "| 7 | Out-of-range numeric values | Validity |\n",
    "| 8 | Nested spending_behavior field | Consistency |\n",
    "| 9 | Redundant income field (annual_salary vs annual_income) | Consistency |\n",
    "\n",
    "One structural fix is applied at load time before any section checks:\n",
    "- **ZIP code** cast to string to prevent float coercion from the single missing value in that column\n",
    "\n",
    "**How to read each section:** risk explanation → count of affected records (n and %) → remediation applied.\n",
    "\n",
    "**How to use this notebook:** Run all cells top-to-bottom. `df_clean` carries all fixes forward and is saved to `data/cleaned_credit_applications.csv` at the end so the bias analysis and privacy notebooks can load it directly."
   ]
  },
  {
   "cell_type": "code",
   "id": "31qw9m25vfj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:42.467274Z",
     "iopub.status.busy": "2026-02-28T01:37:42.466273Z",
     "iopub.status.idle": "2026-02-28T01:37:42.996434Z",
     "shell.execute_reply": "2026-02-28T01:37:42.995420Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:38.721289Z",
     "start_time": "2026-03-01T15:12:38.720073Z"
    }
   },
   "source": [
    "# Imports\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "from datetime import date\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8h47vovnqxa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:42.999742Z",
     "iopub.status.busy": "2026-02-28T01:37:42.998745Z",
     "iopub.status.idle": "2026-02-28T01:37:43.037345Z",
     "shell.execute_reply": "2026-02-28T01:37:43.036336Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:38.740929Z",
     "start_time": "2026-03-01T15:12:38.728736Z"
    }
   },
   "source": [
    "# Load JSON data\n",
    "with open(\"../data/raw_credit_applications.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Normalize JSON into a flat table\n",
    "df = pd.json_normalize(data)\n",
    "n = len(df)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       _id                                  spending_behavior  \\\n",
       "0  app_200  [{'category': 'Shopping', 'amount': 480}, {'ca...   \n",
       "1  app_037  [{'category': 'Rent', 'amount': 608}, {'catego...   \n",
       "2  app_215              [{'category': 'Rent', 'amount': 109}]   \n",
       "\n",
       "   processing_timestamp applicant_info.full_name       applicant_info.email  \\\n",
       "0  2024-01-15T00:00:00Z              Jerry Smith  jerry.smith17@hotmail.com   \n",
       "1                   NaN           Brandon Walker  brandon.walker2@yahoo.com   \n",
       "2                   NaN              Scott Moore     scott.moore94@mail.com   \n",
       "\n",
       "  applicant_info.ssn applicant_info.ip_address applicant_info.gender  \\\n",
       "0        596-64-4340            192.168.48.155                  Male   \n",
       "1        425-69-4784              10.1.102.112                     M   \n",
       "2        370-78-5178            10.240.193.250                  Male   \n",
       "\n",
       "  applicant_info.date_of_birth applicant_info.zip_code  ...  \\\n",
       "0                   2001-03-09                   10036  ...   \n",
       "1                   1992-03-31                   10032  ...   \n",
       "2                   1989-10-24                   10075  ...   \n",
       "\n",
       "  financials.credit_history_months  financials.debt_to_income  \\\n",
       "0                               23                       0.20   \n",
       "1                               51                       0.18   \n",
       "2                               41                       0.21   \n",
       "\n",
       "   financials.savings_balance  decision.loan_approved  \\\n",
       "0                       31212                   False   \n",
       "1                       17915                   False   \n",
       "2                       37909                    True   \n",
       "\n",
       "   decision.rejection_reason loan_purpose decision.interest_rate  \\\n",
       "0       algorithm_risk_score          NaN                    NaN   \n",
       "1       algorithm_risk_score          NaN                    NaN   \n",
       "2                        NaN     vacation                    3.7   \n",
       "\n",
       "   decision.approved_amount  financials.annual_salary  notes  \n",
       "0                       NaN                       NaN    NaN  \n",
       "1                       NaN                       NaN    NaN  \n",
       "2                   59000.0                       NaN    NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>spending_behavior</th>\n",
       "      <th>processing_timestamp</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>applicant_info.email</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <th>...</th>\n",
       "      <th>financials.credit_history_months</th>\n",
       "      <th>financials.debt_to_income</th>\n",
       "      <th>financials.savings_balance</th>\n",
       "      <th>decision.loan_approved</th>\n",
       "      <th>decision.rejection_reason</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_200</td>\n",
       "      <td>[{'category': 'Shopping', 'amount': 480}, {'ca...</td>\n",
       "      <td>2024-01-15T00:00:00Z</td>\n",
       "      <td>Jerry Smith</td>\n",
       "      <td>jerry.smith17@hotmail.com</td>\n",
       "      <td>596-64-4340</td>\n",
       "      <td>192.168.48.155</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-03-09</td>\n",
       "      <td>10036</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>31212</td>\n",
       "      <td>False</td>\n",
       "      <td>algorithm_risk_score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_037</td>\n",
       "      <td>[{'category': 'Rent', 'amount': 608}, {'catego...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Walker</td>\n",
       "      <td>brandon.walker2@yahoo.com</td>\n",
       "      <td>425-69-4784</td>\n",
       "      <td>10.1.102.112</td>\n",
       "      <td>M</td>\n",
       "      <td>1992-03-31</td>\n",
       "      <td>10032</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.18</td>\n",
       "      <td>17915</td>\n",
       "      <td>False</td>\n",
       "      <td>algorithm_risk_score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_215</td>\n",
       "      <td>[{'category': 'Rent', 'amount': 109}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scott Moore</td>\n",
       "      <td>scott.moore94@mail.com</td>\n",
       "      <td>370-78-5178</td>\n",
       "      <td>10.240.193.250</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-10-24</td>\n",
       "      <td>10075</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>37909</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vacation</td>\n",
       "      <td>3.7</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "5xysyds265x",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Duplicate Records\n",
    "\n",
    "Risk: If the same application is entered more than once (due to errors, fraud, or resubmission), it can artificially increase the total number of applications and distort statistics such as approval rates. Duplicate applications can signal problems in the data processing pipeline or deliberate attempts to game the system.\n",
    "\n",
    "We check two signals:\n",
    "- Duplicate application IDs (_id): the primary key must be unique\n",
    "- Duplicate name and email combinations: the same person applying more than once"
   ]
  },
  {
   "cell_type": "code",
   "id": "jbfwm6ylds",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.052671Z",
     "iopub.status.busy": "2026-02-28T01:37:43.051671Z",
     "iopub.status.idle": "2026-02-28T01:37:43.068207Z",
     "shell.execute_reply": "2026-02-28T01:37:43.067694Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:38.835096Z",
     "start_time": "2026-03-01T15:12:38.829586Z"
    }
   },
   "source": [
    "# Check and report duplicate records by application ID and by name + email combination\n",
    "dup_id    = df['_id'].duplicated(keep=False)\n",
    "dup_combo = df.duplicated(subset=['applicant_info.full_name', 'applicant_info.email'], keep=False)\n",
    "\n",
    "# Print count of duplicates for each type\n",
    "print(f\"Duplicate application IDs:      {dup_id.sum()} records  ({dup_id.sum()/len(df):.1%})\")\n",
    "print(f\"Duplicate name + email:         {dup_combo.sum()} records  ({dup_combo.sum()/len(df):.1%})\")\n",
    "\n",
    "# Display duplicate records for manual review\n",
    "if (dup_id | dup_combo).any():\n",
    "    display(df[dup_id | dup_combo][['_id', 'applicant_info.full_name', 'applicant_info.email']])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate application IDs:      4 records  (0.8%)\n",
      "Duplicate name + email:         4 records  (0.8%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         _id applicant_info.full_name         applicant_info.email\n",
       "8    app_042             Joseph Lopez      joseph.lopez1@gmail.com\n",
       "354  app_042             Joseph Lopez      joseph.lopez1@gmail.com\n",
       "383  app_001         Stephanie Nguyen  stephanie.nguyen47@mail.com\n",
       "455  app_001         Stephanie Nguyen  stephanie.nguyen47@mail.com"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>applicant_info.email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>app_042</td>\n",
       "      <td>Joseph Lopez</td>\n",
       "      <td>joseph.lopez1@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>app_042</td>\n",
       "      <td>Joseph Lopez</td>\n",
       "      <td>joseph.lopez1@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>app_001</td>\n",
       "      <td>Stephanie Nguyen</td>\n",
       "      <td>stephanie.nguyen47@mail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>app_001</td>\n",
       "      <td>Stephanie Nguyen</td>\n",
       "      <td>stephanie.nguyen47@mail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "t0ngo6c48vn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.072225Z",
     "iopub.status.busy": "2026-02-28T01:37:43.072225Z",
     "iopub.status.idle": "2026-02-28T01:37:43.079405Z",
     "shell.execute_reply": "2026-02-28T01:37:43.078250Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:38.901444Z",
     "start_time": "2026-03-01T15:12:38.899307Z"
    }
   },
   "source": [
    "# Remove duplicate application IDs, keeping only the first occurrence\n",
    "# .copy() ensures df_clean is an independent DataFrame (prevents SettingWithCopyWarning)\n",
    "df_clean = df.drop_duplicates(subset='_id', keep='first').copy()\n",
    "print(f\"After deduplication: {len(df_clean)} records  (removed {n - len(df_clean)})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deduplication: 500 records  (removed 2)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "omhk92suob",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Missing Values\n",
    "\n",
    "**Risk:** Missing values in critical fields make records unusable for lending decisions and can introduce bias if missingness is non-random (e.g. if lower-income applicants disproportionately have income missing)."
   ]
  },
  {
   "cell_type": "code",
   "id": "irz8xna5l",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.082480Z",
     "iopub.status.busy": "2026-02-28T01:37:43.081480Z",
     "iopub.status.idle": "2026-02-28T01:37:43.095142Z",
     "shell.execute_reply": "2026-02-28T01:37:43.095142Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:38.928300Z",
     "start_time": "2026-03-01T15:12:38.923401Z"
    }
   },
   "source": [
    "# Count missing values per column and sort by frequency\n",
    "missing_count = df_clean.isnull().sum()\n",
    "missing_pct   = missing_count / len(df_clean) * 100\n",
    "\n",
    "missing_report = (\n",
    "    pd.DataFrame({'missing_count': missing_count, 'missing_%': missing_pct.round(1)})\n",
    "    .query('missing_count > 0')\n",
    "    .sort_values('missing_%', ascending=False)\n",
    ")\n",
    "display(missing_report)\n",
    "\n",
    "print(\"\\nNote: financials.annual_salary shows 99% missing because only 5 records use it\")\n",
    "print(\"instead of annual_income; these two fields represent the same concept and are\")\n",
    "print(\"consolidated into annual_income in Section 9.\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           missing_count  missing_%\n",
       "notes                                500      100.0\n",
       "financials.annual_salary             495       99.0\n",
       "loan_purpose                         450       90.0\n",
       "processing_timestamp                 438       87.6\n",
       "decision.rejection_reason            292       58.4\n",
       "decision.interest_rate               208       41.6\n",
       "decision.approved_amount             208       41.6\n",
       "financials.annual_income               5        1.0\n",
       "applicant_info.ssn                     4        0.8\n",
       "applicant_info.ip_address              4        0.8"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>500</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <td>495</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_purpose</th>\n",
       "      <td>450</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing_timestamp</th>\n",
       "      <td>438</td>\n",
       "      <td>87.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.rejection_reason</th>\n",
       "      <td>292</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <td>208</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <td>208</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_income</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: financials.annual_salary shows 99% missing because only 5 records use it\n",
      "instead of annual_income; these two fields represent the same concept and are\n",
      "consolidated into annual_income in Section 9.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "hgsc0ti7gv",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.099150Z",
     "iopub.status.busy": "2026-02-28T01:37:43.099150Z",
     "iopub.status.idle": "2026-02-28T01:37:43.107056Z",
     "shell.execute_reply": "2026-02-28T01:37:43.106020Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:38.953122Z",
     "start_time": "2026-03-01T15:12:38.950153Z"
    }
   },
   "source": [
    "# Define fields required for a valid lending decision\n",
    "critical_fields = [\n",
    "    'applicant_info.full_name',\n",
    "    'applicant_info.email',\n",
    "    'financials.annual_income',\n",
    "    'financials.credit_history_months',\n",
    "]\n",
    "\n",
    "# Flag records missing at least one critical field\n",
    "df_clean.loc[:, 'has_critical_missing'] = df_clean[critical_fields].isnull().any(axis=1)\n",
    "print(f\"Records missing at least one critical field: {df_clean['has_critical_missing'].sum()}  ({df_clean['has_critical_missing'].mean():.1%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records missing at least one critical field: 5  (1.0%)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "rfc258adqtt",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Wrong Data Types\n",
    "\n",
    "**Risk:** Financial fields stored as text (e.g. `\"73000\"` instead of `73000`) cannot be used in calculations. Coercing them to numbers may silently convert corrupt string entries into `NaN`, so we log what changes before and after."
   ]
  },
  {
   "cell_type": "code",
   "id": "o9pibpy9k4j",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.110012Z",
     "iopub.status.busy": "2026-02-28T01:37:43.110012Z",
     "iopub.status.idle": "2026-02-28T01:37:43.117353Z",
     "shell.execute_reply": "2026-02-28T01:37:43.117092Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:38.976592Z",
     "start_time": "2026-03-01T15:12:38.973893Z"
    }
   },
   "source": [
    "# Define the financial columns that should be numeric\n",
    "numeric_fields = [\n",
    "    'financials.annual_income',\n",
    "    'financials.credit_history_months',\n",
    "    'financials.debt_to_income',\n",
    "    'financials.savings_balance',\n",
    "]\n",
    "\n",
    "def is_non_numeric(val):\n",
    "    return not isinstance(val, (int, float)) and pd.notna(val)\n",
    "\n",
    "# Report non-numeric entries per field before coercion\n",
    "print(\"Non-numeric entries per field (before coercion):\")\n",
    "for col in numeric_fields:\n",
    "    non_numeric = df_clean[col].apply(is_non_numeric)\n",
    "    label = col.split('.')[-1]\n",
    "    print(f\"  {label:<25}  {non_numeric.sum()} records  ({non_numeric.sum()/len(df_clean):.1%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric entries per field (before coercion):\n",
      "  annual_income              8 records  (1.6%)\n",
      "  credit_history_months      0 records  (0.0%)\n",
      "  debt_to_income             0 records  (0.0%)\n",
      "  savings_balance            0 records  (0.0%)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "32w81vbgz9o",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.121362Z",
     "iopub.status.busy": "2026-02-28T01:37:43.121362Z",
     "iopub.status.idle": "2026-02-28T01:37:43.129509Z",
     "shell.execute_reply": "2026-02-28T01:37:43.128394Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:38.990468Z",
     "start_time": "2026-03-01T15:12:38.987361Z"
    }
   },
   "source": [
    "# Force all financial fields to numeric; unparseable entries become NaN\n",
    "for col in numeric_fields:\n",
    "    df_clean.loc[:, col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Confirm data types after coercion\n",
    "print(\"Data types confirmed after coercion:\")\n",
    "print(df_clean[numeric_fields].dtypes.to_string())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types confirmed after coercion:\n",
      "financials.annual_income             object\n",
      "financials.credit_history_months      int64\n",
      "financials.debt_to_income           float64\n",
      "financials.savings_balance            int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "bfko3fhla9l",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Invalid Values\n",
    "\n",
    "**Risk:** Values that are present but logically impossible (a negative credit history, a future date of birth, a garbled email) corrupt downstream analysis just as much as missing values. We detect and nullify them."
   ]
  },
  {
   "cell_type": "code",
   "id": "y33ikpkrrn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.133511Z",
     "iopub.status.busy": "2026-02-28T01:37:43.132509Z",
     "iopub.status.idle": "2026-02-28T01:37:43.143805Z",
     "shell.execute_reply": "2026-02-28T01:37:43.143532Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.000710Z",
     "start_time": "2026-03-01T15:12:38.996213Z"
    }
   },
   "source": [
    "# Flag negative credit history (cannot have fewer than 0 months)\n",
    "neg_credit = df_clean['financials.credit_history_months'] < 0\n",
    "\n",
    "# Parse date of birth and flag values outside a plausible age range\n",
    "dob         = pd.to_datetime(df_clean['applicant_info.date_of_birth'], errors='coerce')\n",
    "today       = pd.Timestamp(date.today())\n",
    "age         = (today - dob).dt.days / 365.25\n",
    "future_dob  = dob > today\n",
    "too_old     = age > 100\n",
    "invalid_dob = future_dob | too_old\n",
    "\n",
    "print(f\"Negative credit history months:  {neg_credit.sum()}  ({neg_credit.sum()/len(df_clean):.1%})\")\n",
    "print(f\"Future date of birth:            {future_dob.sum()}  ({future_dob.sum()/len(df_clean):.1%})\")\n",
    "print(f\"Age > 100 years:                 {too_old.sum()}  ({too_old.sum()/len(df_clean):.1%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative credit history months:  2  (0.4%)\n",
      "Future date of birth:            0  (0.0%)\n",
      "Age > 100 years:                 0  (0.0%)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "kp5nxl3ao4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.147845Z",
     "iopub.status.busy": "2026-02-28T01:37:43.146815Z",
     "iopub.status.idle": "2026-02-28T01:37:43.154110Z",
     "shell.execute_reply": "2026-02-28T01:37:43.152818Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.009183Z",
     "start_time": "2026-03-01T15:12:39.006368Z"
    }
   },
   "source": [
    "# Define email pattern and flag malformed addresses (must follow user@domain.tld)\n",
    "EMAIL_RE = re.compile(r'^[\\w\\.\\+\\-]+@[\\w\\-]+\\.[a-zA-Z]{2,}$')\n",
    "\n",
    "def is_bad_email(val):\n",
    "    if pd.isna(val):\n",
    "        return False\n",
    "    return not bool(EMAIL_RE.match(str(val)))\n",
    "\n",
    "bad_email = df_clean['applicant_info.email'].apply(is_bad_email)\n",
    "print(f\"Malformed emails:  {bad_email.sum()}  ({bad_email.sum()/len(df_clean):.1%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed emails:  11  (2.2%)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "a5vtjj36ug7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.157110Z",
     "iopub.status.busy": "2026-02-28T01:37:43.157110Z",
     "iopub.status.idle": "2026-02-28T01:37:43.165144Z",
     "shell.execute_reply": "2026-02-28T01:37:43.165144Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.020561Z",
     "start_time": "2026-03-01T15:12:39.017144Z"
    }
   },
   "source": [
    "# Define SSN pattern and flag malformed entries (US format must be NNN-NN-NNNN)\n",
    "SSN_RE = re.compile(r'^\\d{3}-\\d{2}-\\d{4}$')\n",
    "\n",
    "def is_bad_ssn(val):\n",
    "    if pd.isna(val):\n",
    "        return False\n",
    "    return not bool(SSN_RE.match(str(val)))\n",
    "\n",
    "bad_ssn = df_clean['applicant_info.ssn'].apply(is_bad_ssn)\n",
    "print(f\"Malformed SSNs:  {bad_ssn.sum()}  ({bad_ssn.sum()/len(df_clean):.1%})\")\n",
    "\n",
    "# Set impossible and malformed values to NaN\n",
    "df_clean.loc[neg_credit,  'financials.credit_history_months'] = float('nan')\n",
    "df_clean.loc[invalid_dob, 'applicant_info.date_of_birth']     = float('nan')\n",
    "df_clean.loc[bad_email,   'applicant_info.email']             = float('nan')\n",
    "df_clean.loc[bad_ssn,     'applicant_info.ssn']               = float('nan')\n",
    "print(\"Impossible and malformed values set to NaN.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformed SSNs:  0  (0.0%)\n",
      "Impossible and malformed values set to NaN.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "rbbwa83pd6",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Inconsistent Categorical Values\n",
    "\n",
    "**Risk:** The same gender can appear as `\"Male\"`, `\"M\"`, or `\"male\"`. Without standardisation, any group-level analysis (e.g. approval rates by gender) will split the same group into separate buckets, making results misleading."
   ]
  },
  {
   "cell_type": "code",
   "id": "fhrt9pywy16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.168156Z",
     "iopub.status.busy": "2026-02-28T01:37:43.168156Z",
     "iopub.status.idle": "2026-02-28T01:37:43.173156Z",
     "shell.execute_reply": "2026-02-28T01:37:43.173156Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.028314Z",
     "start_time": "2026-03-01T15:12:39.025992Z"
    }
   },
   "source": [
    "# Show raw gender values before standardisation\n",
    "print(\"Raw gender values in dataset:\")\n",
    "print(df_clean['applicant_info.gender'].value_counts(dropna=False).to_string())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw gender values in dataset:\n",
      "applicant_info.gender\n",
      "Male      194\n",
      "Female    193\n",
      "F          58\n",
      "M          53\n",
      "            2\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "sryh8knd1o",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.176538Z",
     "iopub.status.busy": "2026-02-28T01:37:43.176538Z",
     "iopub.status.idle": "2026-02-28T01:37:43.184350Z",
     "shell.execute_reply": "2026-02-28T01:37:43.184350Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.037878Z",
     "start_time": "2026-03-01T15:12:39.034938Z"
    }
   },
   "source": [
    "# Map all spelling variants to a canonical two-value vocabulary\n",
    "GENDER_MAP = {\n",
    "    'Male':   'Male',   'male':   'Male',   'M': 'Male',   'm': 'Male',\n",
    "    'Female': 'Female', 'female': 'Female', 'F': 'Female', 'f': 'Female',\n",
    "}\n",
    "df_clean.loc[:, 'applicant_info.gender_clean'] = df_clean['applicant_info.gender'].map(GENDER_MAP)\n",
    "\n",
    "# Count variants that could not be mapped\n",
    "unmapped = df_clean['applicant_info.gender_clean'].isna() & df_clean['applicant_info.gender'].notna()\n",
    "print(f\"Variants that could not be mapped to Male/Female: {unmapped.sum()}  ({unmapped.sum()/len(df_clean):.1%})\")\n",
    "\n",
    "# Show cleaned gender distribution\n",
    "print(\"\\nCleaned gender distribution:\")\n",
    "print(df_clean['applicant_info.gender_clean'].value_counts(dropna=False).to_string())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variants that could not be mapped to Male/Female: 2  (0.4%)\n",
      "\n",
      "Cleaned gender distribution:\n",
      "applicant_info.gender_clean\n",
      "Female    251\n",
      "Male      247\n",
      "NaN         2\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "s3gkqp90vp",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Mixed Date Formats\n",
    "\n",
    "**Risk:** The same field contains dates written in multiple formats (`YYYY-MM-DD`, `DD/MM/YYYY`, `MM/DD/YYYY`, etc.). Parsing without standardisation produces wrong ages or silently drops records."
   ]
  },
  {
   "cell_type": "code",
   "id": "cints6u6czn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.188375Z",
     "iopub.status.busy": "2026-02-28T01:37:43.188375Z",
     "iopub.status.idle": "2026-02-28T01:37:43.196811Z",
     "shell.execute_reply": "2026-02-28T01:37:43.196811Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.048099Z",
     "start_time": "2026-03-01T15:12:39.044458Z"
    }
   },
   "source": [
    "# Define known date format patterns for recognition\n",
    "DATE_FORMATS = {\n",
    "    r'^\\d{4}-\\d{2}-\\d{2}$':   'YYYY-MM-DD (ISO standard)',\n",
    "    r'^\\d{2}/\\d{2}/\\d{4}$':   'DD/MM/YYYY or MM/DD/YYYY',\n",
    "    r'^\\d{2}-\\d{2}-\\d{4}$':   'DD-MM-YYYY',\n",
    "    r'^\\d{2}\\.\\d{2}\\.\\d{4}$': 'DD.MM.YYYY',\n",
    "    r'^\\w+ \\d{1,2},? \\d{4}$': 'Month D YYYY (text)',\n",
    "}\n",
    "\n",
    "raw_dob   = df_clean['applicant_info.date_of_birth'].dropna().astype(str)\n",
    "remaining = len(raw_dob)\n",
    "\n",
    "# Count records matching each date format pattern; only print formats present in the data\n",
    "print(\"Date format distribution:\")\n",
    "for pattern, label in DATE_FORMATS.items():\n",
    "    count      = raw_dob.str.match(pattern).sum()\n",
    "    remaining -= count\n",
    "    if count > 0:\n",
    "        print(f\"  {label:<35}  {count:>4} records  ({count/len(df_clean):.1%})\")\n",
    "print(f\"  {'Unrecognised':<35}  {remaining:>4} records  ({remaining/len(df_clean):.1%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date format distribution:\n",
      "  YYYY-MM-DD (ISO standard)             339 records  (67.8%)\n",
      "  DD/MM/YYYY or MM/DD/YYYY              101 records  (20.2%)\n",
      "  Unrecognised                           60 records  (12.0%)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "98vozo17d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.199819Z",
     "iopub.status.busy": "2026-02-28T01:37:43.199819Z",
     "iopub.status.idle": "2026-02-28T01:37:43.207622Z",
     "shell.execute_reply": "2026-02-28T01:37:43.207111Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.056301Z",
     "start_time": "2026-03-01T15:12:39.053538Z"
    }
   },
   "source": [
    "# Parse all date formats into a single consistent datetime column\n",
    "df_clean.loc[:, 'applicant_info.date_of_birth_parsed'] = pd.to_datetime(\n",
    "    df_clean['applicant_info.date_of_birth'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Report how many dates remain unparseable\n",
    "still_null = df_clean['applicant_info.date_of_birth_parsed'].isna().sum()\n",
    "print(f\"Records where date still could not be parsed: {still_null}  ({still_null/len(df_clean):.1%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records where date still could not be parsed: 161  (32.2%)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "htof0jzi5h",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Out-of-Range Numeric Values\n",
    "\n",
    "**Risk:** Values that are numeric and parseable but structurally impossible (a debt-to-income ratio above 1, a negative savings balance, or zero/negative income) corrupt averages and any model trained on the data. We also flag extreme statistical outliers (more than 3 standard deviations from the mean income) for analyst review. Unlike structurally impossible values, outliers are *not* automatically removed. They are retained in `df_clean` to inspect before modelling."
   ]
  },
  {
   "cell_type": "code",
   "id": "j03qjiat6r",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.210633Z",
     "iopub.status.busy": "2026-02-28T01:37:43.210633Z",
     "iopub.status.idle": "2026-02-28T01:37:43.215847Z",
     "shell.execute_reply": "2026-02-28T01:37:43.215847Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.065287Z",
     "start_time": "2026-03-01T15:12:39.062090Z"
    }
   },
   "source": [
    "def is_invalid_dti(val):\n",
    "    return pd.notna(val) and not (0 <= val <= 1)\n",
    "\n",
    "# Flag debt-to-income ratios outside the valid range [0, 1]\n",
    "dti_out = df_clean['financials.debt_to_income'].apply(is_invalid_dti)\n",
    "\n",
    "# Flag negative savings balances and zero or negative income\n",
    "neg_savings = df_clean['financials.savings_balance'] < 0\n",
    "neg_income  = df_clean['financials.annual_income']   <= 0\n",
    "\n",
    "print(f\"Debt-to-income ratio outside [0, 1]:  {dti_out.sum()}  ({dti_out.sum()/len(df_clean):.1%})\")\n",
    "print(f\"Negative savings balance:             {neg_savings.sum()}  ({neg_savings.sum()/len(df_clean):.1%})\")\n",
    "print(f\"Zero or negative annual income:       {neg_income.sum()}  ({neg_income.sum()/len(df_clean):.1%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debt-to-income ratio outside [0, 1]:  1  (0.2%)\n",
      "Negative savings balance:             1  (0.2%)\n",
      "Zero or negative annual income:       1  (0.2%)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "p9axwgl8xil",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.218854Z",
     "iopub.status.busy": "2026-02-28T01:37:43.218854Z",
     "iopub.status.idle": "2026-02-28T01:37:43.226171Z",
     "shell.execute_reply": "2026-02-28T01:37:43.225162Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.073513Z",
     "start_time": "2026-03-01T15:12:39.070672Z"
    }
   },
   "source": [
    "# Flag income statistical outliers: more than 3 standard deviations from the mean\n",
    "income_mean     = df_clean['financials.annual_income'].mean()\n",
    "income_std      = df_clean['financials.annual_income'].std()\n",
    "income_outliers = (df_clean['financials.annual_income'] - income_mean).abs() > 3 * income_std\n",
    "\n",
    "print(f\"Income statistical outliers (> 3σ):   {income_outliers.sum()}  ({income_outliers.sum()/len(df_clean):.1%})\")\n",
    "print(f\"Income range: ${df_clean['financials.annual_income'].min():,.0f} to ${df_clean['financials.annual_income'].max():,.0f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income statistical outliers (> 3σ):   2  (0.4%)\n",
      "Income range: $0 to $171,000\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "g1ztpwdv4om",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.228169Z",
     "iopub.status.busy": "2026-02-28T01:37:43.228169Z",
     "iopub.status.idle": "2026-02-28T01:37:43.233456Z",
     "shell.execute_reply": "2026-02-28T01:37:43.233456Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.080744Z",
     "start_time": "2026-03-01T15:12:39.077927Z"
    }
   },
   "source": [
    "# Set structurally impossible values to NaN; statistical outliers are flagged but kept\n",
    "df_clean.loc[dti_out,    'financials.debt_to_income']  = float('nan')\n",
    "df_clean.loc[neg_savings,'financials.savings_balance'] = float('nan')\n",
    "df_clean.loc[neg_income, 'financials.annual_income']   = float('nan')\n",
    "print(\"Impossible values set to NaN. Outliers retained for analyst review before modelling.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible values set to NaN. Outliers retained for analyst review before modelling.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "4wg0olq94we",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Nested `spending_behavior`: Flattening to Wide Format\n",
    "\n",
    "**Risk:** The `spending_behavior` field arrives from JSON as a list of `{category, amount}` objects. Keeping it as a raw list makes the column unreadable in CSV and unusable for any numerical analysis. We pivot each unique category into its own numeric column (`spending_<Category>`); applicants without a given category receive `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "id": "d2orxfqeqyd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.236462Z",
     "iopub.status.busy": "2026-02-28T01:37:43.236462Z",
     "iopub.status.idle": "2026-02-28T01:37:43.241997Z",
     "shell.execute_reply": "2026-02-28T01:37:43.241701Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.086295Z",
     "start_time": "2026-03-01T15:12:39.084442Z"
    }
   },
   "source": [
    "def parse_spending(val):\n",
    "    # Accept either a Python list (direct from JSON) or a repr string (reloaded from CSV)\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def entries_to_dict(entries):\n",
    "    # Convert a list of {category, amount} objects into a flat {spending_Category: amount} dict\n",
    "    return {f\"spending_{e['category']}\": e['amount'] for e in entries}"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "vnrlt9e96w",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.245006Z",
     "iopub.status.busy": "2026-02-28T01:37:43.245006Z",
     "iopub.status.idle": "2026-02-28T01:37:43.305600Z",
     "shell.execute_reply": "2026-02-28T01:37:43.305600Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.111716Z",
     "start_time": "2026-03-01T15:12:39.090323Z"
    }
   },
   "source": [
    "# Parse the spending list and pivot each category into its own column\n",
    "spending_wide = (\n",
    "    df_clean['spending_behavior']\n",
    "    .apply(parse_spending)\n",
    "    .apply(entries_to_dict)\n",
    "    .apply(pd.Series)\n",
    ")\n",
    "\n",
    "categories = sorted(c.replace('spending_', '') for c in spending_wide.columns)\n",
    "print(f\"Spending categories found ({len(categories)}): {categories}\")\n",
    "print(f\"\\nRecords with at least one spending entry: \"\n",
    "      f\"{spending_wide.notna().any(axis=1).sum()}  \"\n",
    "      f\"({spending_wide.notna().any(axis=1).sum()/len(df_clean):.1%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spending categories found (15): ['Adult Entertainment', 'Alcohol', 'Dining', 'Education', 'Entertainment', 'Fitness', 'Gambling', 'Groceries', 'Healthcare', 'Insurance', 'Rent', 'Shopping', 'Transportation', 'Travel', 'Utilities']\n",
      "\n",
      "Records with at least one spending entry: 500  (100.0%)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "ran9swo4w5l",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.309819Z",
     "iopub.status.busy": "2026-02-28T01:37:43.308817Z",
     "iopub.status.idle": "2026-02-28T01:37:43.316198Z",
     "shell.execute_reply": "2026-02-28T01:37:43.316198Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.118229Z",
     "start_time": "2026-03-01T15:12:39.114954Z"
    }
   },
   "source": [
    "# Replace the raw nested column with flat numeric columns\n",
    "df_clean = df_clean.drop(columns=['spending_behavior']).join(spending_wide)\n",
    "print(f\"df_clean shape after flattening spending_behavior: {df_clean.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_clean shape after flattening spending_behavior: (500, 38)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "bc809x4swgg",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Redundant Income Field: annual_salary vs annual_income\n",
    "\n",
    "**Dimension:** Consistency  \n",
    "**Risk:** Five records populate `annual_salary` instead of `annual_income` to record the applicant's income. Both columns represent the same concept under two different names. Aggregations on `annual_income` alone silently exclude these five records, biasing any income-based statistics or model features."
   ]
  },
  {
   "cell_type": "code",
   "id": "6tydgvnpbzi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.320209Z",
     "iopub.status.busy": "2026-02-28T01:37:43.319212Z",
     "iopub.status.idle": "2026-02-28T01:37:43.330323Z",
     "shell.execute_reply": "2026-02-28T01:37:43.330040Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.127556Z",
     "start_time": "2026-03-01T15:12:39.123408Z"
    }
   },
   "source": [
    "# Identify records where annual_salary is filled and annual_income is null\n",
    "salary_mask = df_clean['financials.annual_salary'].notna()\n",
    "\n",
    "print(f\"Records with annual_salary present:           {salary_mask.sum()}\")\n",
    "print(f\"Of those, annual_income is also null:         {(salary_mask & df_clean['financials.annual_income'].isna()).sum()}\")\n",
    "print()\n",
    "display(df_clean.loc[salary_mask, ['_id', 'financials.annual_income', 'financials.annual_salary']])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with annual_salary present:           5\n",
      "Of those, annual_income is also null:         5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         _id financials.annual_income  financials.annual_salary\n",
       "76   app_436                      NaN                   45000.0\n",
       "94   app_421                      NaN                   46000.0\n",
       "99   app_479                      NaN                   94000.0\n",
       "141  app_463                      NaN                   86000.0\n",
       "149  app_449                      NaN                   75000.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>financials.annual_income</th>\n",
       "      <th>financials.annual_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>app_436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>app_421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>app_479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>app_463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>app_449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "11mcu24c27uo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.333332Z",
     "iopub.status.busy": "2026-02-28T01:37:43.333332Z",
     "iopub.status.idle": "2026-02-28T01:37:43.339438Z",
     "shell.execute_reply": "2026-02-28T01:37:43.339438Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.161538Z",
     "start_time": "2026-03-01T15:12:39.158832Z"
    }
   },
   "source": [
    "# Copy annual_salary into annual_income where income is missing\n",
    "df_clean.loc[salary_mask, 'financials.annual_income'] = df_clean.loc[salary_mask, 'financials.annual_salary']\n",
    "\n",
    "# Drop the redundant annual_salary column\n",
    "df_clean = df_clean.drop(columns=['financials.annual_salary'])\n",
    "\n",
    "print(f\"annual_salary values merged into annual_income. Column dropped.\")\n",
    "print(f\"df_clean shape: {df_clean.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual_salary values merged into annual_income. Column dropped.\n",
      "df_clean shape: (500, 37)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "0mw3l3i1k8rk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T01:37:43.342447Z",
     "iopub.status.busy": "2026-02-28T01:37:43.342447Z",
     "iopub.status.idle": "2026-02-28T01:37:43.364785Z",
     "shell.execute_reply": "2026-02-28T01:37:43.363778Z"
    },
    "ExecuteTime": {
     "end_time": "2026-03-01T15:12:39.195054Z",
     "start_time": "2026-03-01T15:12:39.182006Z"
    }
   },
   "source": [
    "# Export the cleaned dataset for use in downstream notebooks\n",
    "out_path = \"../data/cleaned_credit_applications.csv\"\n",
    "df_clean.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved: {out_path}\")\n",
    "print(f\"Shape: {df_clean.shape[0]} rows x {df_clean.shape[1]} columns\")\n",
    "print()\n",
    "print(\"Load in downstream notebooks with:\")\n",
    "print(\"  import pandas as pd\")\n",
    "print(\"  df = pd.read_csv('../data/cleaned_credit_applications.csv',\")\n",
    "print(\"                   dtype={'applicant_info.zip_code': str})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/cleaned_credit_applications.csv\n",
      "Shape: 500 rows x 37 columns\n",
      "\n",
      "Load in downstream notebooks with:\n",
      "  import pandas as pd\n",
      "  df = pd.read_csv('../data/cleaned_credit_applications.csv',\n",
      "                   dtype={'applicant_info.zip_code': str})\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
